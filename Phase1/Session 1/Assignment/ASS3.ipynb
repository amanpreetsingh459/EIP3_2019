{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My info\n",
    "\n",
    "- ** Name : Amanpreet Singh **\n",
    "- ** Email : amanpreetsingh459@gmail.com **\n",
    "- ** Batch number : 8 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Topics:__*\n",
    "\n",
    "1. **Convolution**\n",
    "2. **Filters/Kernels**\n",
    "3. **Feature Maps**\n",
    "4. **3x3 convolution**\n",
    "5. **1x1 convolution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Convolution:\n",
    "\n",
    "Suppose we are in the dark room and we are trying to look at a person standing in front of us with a small torch. As we know that with that small torch we cannot look that person as the whole. We do it like this -- we start from up and move the torch from left-to-right and up-to-down. This way we can take a look at the person as the whole. So **that part of the person which is visible at a single time with the light of the torch is referred as the convolution in CNN theory.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters/Kernels:\n",
    "\n",
    "Taking the example from above (in convolution explanation section -- the dark room, person and the torch) **that light which is coming from the torch and putting on to the person is referred as filter or kernel.** The size of it comprises of the width, height and depth. Though the size of the filter we can define on our own unlike the constant physical torch. Standard is 3x3xdepth (depth typically defines the color channels in the image) as was mentioned in the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Maps:\n",
    "\n",
    "Basically for the computer an image (that person in dark room as per our example) is the matrix of numerical numbers. Convolution comprised of a sub set of those values every time we convolve over the image. The filter is another matrix of the values of some defined size. So **the output (operation performed is typically the sum of products between filter matrix and subset matrix of the image of the same size as filter) received on convolving the image with a particular filter is called a feature map.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3x3 convolution:\n",
    "\n",
    "Filters/Kernels are the feature extractors in a CNN. They perform matrix operation with the image's small region whose size is as that of the filter. The filter size defines how much infoamtion to be gained from the image and how much do we discard. **The 3x3 filter mathematically reduces the dimensions of the image by 2x2.** As 28x28==>> convolve with filter size 3x3 then ==>> 26x26 and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1x1 convolution:\n",
    "\n",
    "**1x1 convolutions are used to decrease the depth of the CNN.** As after each subsequent convolution operation we keep on increasing the depth (or channels). It makes the network very computation expensive. So 1x1 convolution is the rescue.\n",
    "\n",
    "In Convolutional Nets, there is no such thing as “fully-connected layers”. There are only convolution layers with 1x1 convolution kernels and a full connection table.  – Yann LeCun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
