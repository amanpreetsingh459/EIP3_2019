{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2A assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/backpropagation.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/backpropagation.png)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are building your own neural network, you will definitely need to understand how to train it. Backpropagation is a commonly used technique for training neural network. There are many resources explaining the technique, but this post will explain backpropagation with concrete example in a very detailed colorful steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this post, we will build a neural network with three layers:\n",
    "\n",
    "- **Input** layer with two inputs neurons\n",
    "- One **hidden** layer with two neurons \n",
    "- **Output** layer with a single neuron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/nn1.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/nn1.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights, weights, weights\n",
    "\n",
    "Neural network training is about finding weights that minimize prediction error. We usually start our training with a set of randomly generated weights.Then, backpropagation is used to update the weights in an attempt to correctly map arbitrary inputs to outputs.\n",
    "\n",
    "Our initial weights will be as following:\n",
    "`w1 = 0.13`, `w2 = 0.22`, `w3 = 0.14`, `w4 = 0.09`, `w5 = 0.15` and `w6 = 0.16`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_weights.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_weights.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Our dataset has one sample with two inputs and one output. \n",
    "\n",
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_dataset.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_dataset.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our single sample is as following `inputs=[4, 5]` and `output=[2]`.\n",
    "\n",
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_sample.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_sample.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass\n",
    "\n",
    "We will use given weights and inputs to predict the output. Inputs are multiplied by weights; the results are then passed forward to next layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_forward.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_forward.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Error\n",
    "\n",
    "Now, it's time to find out how our network performed by calculating the difference between the actual output and predicted one. It's clear that our network output, or **prediction**, is not even close to **actual output**. We can calculate the difference or the error as following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_error.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_error.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Error\n",
    "\n",
    "Our main goal of the training is to reduce the **error** or the difference between **prediction** and **actual output**. Since **actual output** is constant, \"not changing\", the only way to reduce the error is to change **prediction** value. The question now is, how to change **prediction** value?\n",
    "\n",
    "By decomposing **prediction** into its basic elements we can find that **weights** are the variable elements affecting **prediction** value. In other words, in order to change **prediction** value, we need to change **weights** values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://hmkcode.github.io/images/ai/bp_prediction_elements.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_prediction_elements.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The question now is **how to change\\update the weights value so that the error is reduced?**  \n",
    "> The answer is **Backpropagation!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Backpropagation**\n",
    "\n",
    "**Backpropagation**,  short for \"backward propagation of errors\", is a mechanism used to update the **weights** using [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent). It calculates the gradient of the error function with respect to the neural network's weights. The calculation proceeds backwards through the network.\n",
    "\n",
    "> **Gradient descent** is an iterative optimization algorithm for finding the minimum of a function; in our case we want to minimize th error function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient of the function at the current point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://hmkcode.github.io/images/ai/bp_update_formula.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_update_formula.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to update `w6`, we take the current `w6` and subtract the partial derivative of **error** function with respect to `w6`. Optionally, we multiply the derivative of the **error** function by a selected number to make sure that the new updated **weight** is minimizing the error function; this number is called ***learning rate***. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://hmkcode.github.io/images/ai/bp_w6_update.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_w6_update.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivation of the error function is evaluated by applying the chain rule as following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://hmkcode.github.io/images/ai/bp_error_function_partial_derivative_w6.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_error_function_partial_derivative_w6.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to update `w6` we can apply the following formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://hmkcode.github.io/images/ai/bp_w6_update_closed_form.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_w6_update_closed_form.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can derive the update formula for `w5` and any other weights existing between the output and the hidden layer.\n",
    "\n",
    "<a href=\"http://hmkcode.github.io/images/ai/bp_w5_update_closed_form.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_w5_update_closed_form.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when moving backward to update `w1`, `w2`, `w3` and `w4` existing between input and hidden layer, the partial derivative for the error function with respect to `w1`, for example, will be as following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://hmkcode.github.io/images/ai/bp_error_function_partial_derivative_w1.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_error_function_partial_derivative_w1.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the update formula for the remaining weights `w2`, `w3` and `w4` in the same way. \n",
    "\n",
    "In summary, the update formulas for all weights will be as following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://hmkcode.github.io/images/ai/bp_update_all_weights.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_update_all_weights.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rewrite the update formulas in matrices as following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://hmkcode.github.io/images/ai/bp_update_all_weights_matrix.png\">\n",
    "<img class=\"size-full wp-image-315 aligncenter\" src=\"http://hmkcode.github.io/images/ai/bp_update_all_weights_matrix.png\" alt=\"get-location\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Pass\n",
    "\n",
    "Using derived formulas we can find the new **weights**. \n",
    "\n",
    "> **Learning rate:** is a hyperparameter which means that we need to manually guess its value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_new_weights.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_new_weights.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the new **weights** we will repeat the forward passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_forward_2.png\">\n",
    "![](https://raw.githubusercontent.com/amanpreetsingh459/EIP3_2019/master/Phase1/Session%202/Assignment/images/bp_forward_2.png)\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that the **prediction** `0.76` is a little bit closer to **actual output** than the previously predicted one `0.404`. We can repeat the same process of backward and forward pass until **error** is close or equal to zero. In the below python exercise we have repeated the process for 10 times and got the predicted result as `1.99`. Cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2B assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input array\n",
    "X=np.array([[4,5]])\n",
    "\n",
    "#Output\n",
    "y=np.array([[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variable initialization\n",
    "epoch=10 #Setting training iterations\n",
    "learning_rate=0.03 #Setting learning rate\n",
    "inputlayer_neurons = X.shape[1] #number of features in data set\n",
    "hiddenlayer_neurons = 2 #number of 1st hidden layer's neurons\n",
    "output_neurons = 1 #number of neurons at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10\n",
      "Learning rate: 0.03\n",
      "Input layer neurons: 2\n",
      "Hidden layer neurons: 2\n",
      "Output neurons: 1\n"
     ]
    }
   ],
   "source": [
    "#Variable initialization\n",
    "print(\"Epochs:\",epoch)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "print(\"Input layer neurons:\",inputlayer_neurons)\n",
    "print(\"Hidden layer neurons:\",hiddenlayer_neurons)\n",
    "print(\"Output neurons:\",output_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weight and bias initialization\n",
    "weights_input_to_hidden = np.array([[.13, .14], [.22, .09]]) #np.random.normal(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
    "\n",
    "weights_hidden_to_output = np.array([[.15], [.16]]) #np.random.normal(size=(hiddenlayer_neurons,output_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_input_to_hidden:\n",
      "[[ 0.13  0.14]\n",
      " [ 0.22  0.09]]\n",
      "weights_hidden_to_output\n",
      "[[ 0.15]\n",
      " [ 0.16]]\n",
      "weights_input_to_hidden shape\n",
      "(2, 2)\n",
      "weights_hidden_to_output shape\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"weights_input_to_hidden:\")\n",
    "print(weights_input_to_hidden)\n",
    "print(\"weights_hidden_to_output\")\n",
    "print(weights_hidden_to_output)\n",
    "print(\"weights_input_to_hidden shape\")\n",
    "print(weights_input_to_hidden.shape)\n",
    "print(\"weights_hidden_to_output shape\")\n",
    "print(weights_hidden_to_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 1.62  1.01]]\n",
      "######Output layer output after epoch 1:############\n",
      "[[ 0.4046]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[ 1.27265058]]\n",
      "delta from output layer:\n",
      "[[-1.5954]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.07753644]\n",
      " [-0.04834062]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.22753644]\n",
      " [ 0.20834062]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.0435614  -0.0398864 ]\n",
      " [-0.05445175 -0.04985799]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.1735614   0.1798864 ]\n",
      " [ 0.27445175  0.13985799]]\n",
      "Epoch 2 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 2.06650431  1.41883555]]\n",
      "######Output layer output after epoch 2:############\n",
      "[[ 0.76580611]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[ 0.76161728]]\n",
      "delta from output layer:\n",
      "[[-1.23419389]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.07651401]\n",
      " [-0.05253354]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.30405045]\n",
      " [ 0.26087416]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.04503086 -0.03863632]\n",
      " [-0.05628858 -0.04829539]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.21859226  0.21852271]\n",
      " [ 0.33074033  0.18815339]]\n",
      "Epoch 3 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 2.52807068  1.81485779]]\n",
      "######Output layer output after epoch 3:############\n",
      "[[ 1.24211054]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[ 0.28719822]]\n",
      "delta from output layer:\n",
      "[[-0.75788946]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.05747994]\n",
      " [-0.04126385]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.36153039]\n",
      " [ 0.30213801]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.03288001 -0.02747847]\n",
      " [-0.04110001 -0.03434808]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.25147227  0.24600118]\n",
      " [ 0.37184034  0.22250147]]\n",
      "Epoch 4 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 2.86509077  2.09651206]]\n",
      "######Output layer output after epoch 4:############\n",
      "[[ 1.66925338]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[ 0.05469666]]\n",
      "delta from output layer:\n",
      "[[-0.33074662]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.02842857]\n",
      " [-0.02080243]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.38995897]\n",
      " [ 0.32294044]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.01547731 -0.01281738]\n",
      " [-0.01934664 -0.01602172]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.26694958  0.25881855]\n",
      " [ 0.39118698  0.23852319]]\n",
      "Epoch 5 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 3.02373323  2.22789016]]\n",
      "######Output layer output after epoch 5:############\n",
      "[[ 1.89860771]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[ 0.0051402]]\n",
      "delta from output layer:\n",
      "[[-0.10139229]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.0091975 ]\n",
      " [-0.00677673]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.39915646]\n",
      " [ 0.32971717]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.00485657 -0.00401169]\n",
      " [-0.00607071 -0.00501462]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.27180615  0.26283025]\n",
      " [ 0.39725769  0.24353781]]\n",
      "Epoch 6 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 3.07351303  2.26901001]]\n",
      "######Output layer output after epoch 6:############\n",
      "[[ 1.97494415]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[ 0.0003139]]\n",
      "delta from output layer:\n",
      "[[-0.02505585]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.00231028]\n",
      " [-0.00170556]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.40146675]\n",
      " [ 0.33142273]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.00120709 -0.00099649]\n",
      " [-0.00150886 -0.00124561]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.27301324  0.26382673]\n",
      " [ 0.39876655  0.24478342]]\n",
      "Epoch 7 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 3.08588572  2.27922403]]\n",
      "######Output layer output after epoch 7:############\n",
      "[[ 1.99426715]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[  1.64328041e-05]]\n",
      "delta from output layer:\n",
      "[[-0.00573285]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.00053073]\n",
      " [-0.00039199]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.40199748]\n",
      " [ 0.33181472]]\n",
      "Quantity to be updated in the weights:\n",
      "[[-0.00027655 -0.00022827]\n",
      " [-0.00034569 -0.00028534]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.27328979  0.264055  ]\n",
      " [ 0.39911224  0.24506876]]\n",
      "Epoch 8 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 3.08872037  2.28156379]]\n",
      "######Output layer output after epoch 8:############\n",
      "[[ 1.99871424]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[  8.26585785e-07]]\n",
      "delta from output layer:\n",
      "[[-0.00128576]]\n",
      "Quantity to be updated in the weights:\n",
      "[[ -1.19140333e-04]\n",
      " [ -8.80061121e-05]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.40211662]\n",
      " [ 0.33190273]]\n",
      "Quantity to be updated in the weights:\n",
      "[[ -6.20429200e-05  -5.12095583e-05]\n",
      " [ -7.75536500e-05  -6.40119479e-05]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.27335183  0.26410621]\n",
      " [ 0.39918979  0.24513277]]\n",
      "Epoch 9 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 3.08935631  2.28208869]]\n",
      "######Output layer output after epoch 9:############\n",
      "[[ 1.99971296]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[  4.11952298e-08]]\n",
      "delta from output layer:\n",
      "[[-0.00028704]]\n",
      "Quantity to be updated in the weights:\n",
      "[[ -2.66028225e-05]\n",
      " [ -1.96513430e-05]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.40214322]\n",
      " [ 0.33192238]]\n",
      "Quantity to be updated in the weights:\n",
      "[[ -1.38516165e-05  -1.14328957e-05]\n",
      " [ -1.73145206e-05  -1.42911196e-05]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.27336569  0.26411765]\n",
      " [ 0.39920711  0.24514706]]\n",
      "Epoch 10 ---------------------------------------------------------\n",
      "Hidden layer output:\n",
      "[[ 3.08949829  2.28220588]]\n",
      "######Output layer output after epoch 10:############\n",
      "[[ 1.99993599]]\n",
      "####################\n",
      "Error during first epoch\n",
      "[[  2.04881357e-09]]\n",
      "delta from output layer:\n",
      "[[ -6.40127108e-05]]\n",
      "Quantity to be updated in the weights:\n",
      "[[ -5.93301481e-06]\n",
      " [ -4.38270554e-06]]\n",
      "Updated weights hidden to output layer:\n",
      "[[ 0.40214915]\n",
      " [ 0.33192676]]\n",
      "Quantity to be updated in the weights:\n",
      "[[ -3.08911888e-06  -2.54970381e-06]\n",
      " [ -3.86139860e-06  -3.18712976e-06]]\n",
      "Updated weights from input to hidden layer:\n",
      "[[ 0.27336878  0.2641202 ]\n",
      " [ 0.39921097  0.24515025]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    print(\"Epoch {0} ---------------------------------------------------------\".format(i+1))\n",
    "    #Forward Propogation\n",
    "    hidden_layer_activations = np.dot(X, weights_input_to_hidden)\n",
    "    print(\"Hidden layer output:\")\n",
    "    print(hidden_layer_activations)\n",
    "    output_layer_activations = np.dot(hidden_layer_activations, weights_hidden_to_output)\n",
    "    print(\"######Output layer output after epoch {0}:############\".format(i+1))\n",
    "    print(output_layer_activations)\n",
    "    print(\"####################\")\n",
    "    \n",
    "    error_output_layer = ((output_layer_activations - y)**2) / 2\n",
    "    print(\"Error during first epoch\")\n",
    "    print(error_output_layer)\n",
    "    \n",
    "    delta = output_layer_activations - y\n",
    "    print(\"delta from output layer:\")\n",
    "    print(delta)\n",
    "        \n",
    "    #update steps to update weights from hidden to output\n",
    "    update_quantity = (learning_rate * delta).dot(hidden_layer_activations).T\n",
    "    print(\"Quantity to be updated in the weights:\")\n",
    "    print(update_quantity)\n",
    "        \n",
    "    weights_hidden_to_output -= update_quantity\n",
    "    print(\"Updated weights hidden to output layer:\")\n",
    "    print(weights_hidden_to_output)\n",
    "        \n",
    "    update_quantity = np.dot((learning_rate * delta * X).T, weights_hidden_to_output.T)\n",
    "    print(\"Quantity to be updated in the weights:\")\n",
    "    print(update_quantity)\n",
    "    \n",
    "    #update steps to update weights from input to hidden\n",
    "    weights_input_to_hidden -= update_quantity\n",
    "    print(\"Updated weights from input to hidden layer:\")\n",
    "    print(weights_input_to_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual output : 2\n",
    "#### Below we can see that after every epoch predicted output is reaching closer to the actual output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######Output layer output after epoch 1:############\n",
    "[[ 0.4046]]\n",
    "####################\n",
    "######Output layer output after epoch 2:############\n",
    "[[ 0.76580611]]\n",
    "####################\n",
    "######Output layer output after epoch 3:############\n",
    "[[ 1.24211054]]\n",
    "####################\n",
    "######Output layer output after epoch 4:############\n",
    "[[ 1.66925338]]\n",
    "####################\n",
    "######Output layer output after epoch 5:############\n",
    "[[ 1.89860771]]\n",
    "####################\n",
    "######Output layer output after epoch 6:############\n",
    "[[ 1.97494415]]\n",
    "####################\n",
    "######Output layer output after epoch 7:############\n",
    "[[ 1.99426715]]\n",
    "####################\n",
    "######Output layer output after epoch 8:############\n",
    "[[ 1.99871424]]\n",
    "####################\n",
    "######Output layer output after epoch 9:############\n",
    "[[ 1.99971296]]\n",
    "####################\n",
    "######Output layer output after epoch 10:############\n",
    "[[ 1.99993599]]\n",
    "####################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
